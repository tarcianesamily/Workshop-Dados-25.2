{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMS/XR5go44fAyNGhowKM5S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"K9gahLidWoaI","executionInfo":{"status":"ok","timestamp":1757444536394,"user_tz":180,"elapsed":59,"user":{"displayName":"Patricio","userId":"05419012684212813970"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"628269ad-fa97-458f-83bb-97b7f7edf360"},"outputs":[{"output_type":"stream","name":"stdout","text":["Taxa de Churn (cancelaram): 43.33%\n","Taxa de Retenção (não cancelaram): 56.67%\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Projeto de Machine Learning: Classificação de Nível de Alerta de Incêndio\n","Autora: Tarciane Samily\n","\"\"\"\n","\n","# Importando bibliotecas essenciais\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import joblib\n","\n","# -----------------------------\n","# 1. Obtenção e inspeção dos dados\n","# -----------------------------\n","data = pd.read_csv(\"/content/Forest Fires.csv\")\n","print(\"Amostra inicial dos dados:\")\n","print(data.head())\n","\n","# -----------------------------\n","# 2. Exploração e análise inicial\n","# -----------------------------\n","print(\"\\nInformações gerais:\")\n","data.info()\n","print(\"\\nResumo estatístico:\")\n","print(data.describe())\n","\n","# Transformando alertlevel para maiúsculas\n","data['alertlevel'] = data['alertlevel'].str.upper()\n","\n","# Remover registros com alertlevel 'ORANGE' para simplificação\n","data = data[data['alertlevel'] != 'ORANGE']\n","\n","# Criando nova variável alvo binária com base na mediana da severidade\n","mediana_severity = data['severity'].median()\n","data['alert_binary'] = data['severity'].apply(lambda x: 'HIGH' if x > mediana_severity else 'LOW')\n","\n","print(f\"\\nMediana da severidade: {mediana_severity}\")\n","print(\"Distribuição de alert_binary:\")\n","print(data['alert_binary'].value_counts())\n","\n","# Seleção de features e alvo\n","features_list = ['country', 'severity', 'Duration (days)']\n","target_col = 'alert_binary'\n","df_model = data[features_list + [target_col]]\n","\n","# -----------------------------\n","# 3. Separação de arrays\n","# -----------------------------\n","X = df_model.drop(columns=[target_col]).values\n","y = df_model[target_col].values\n","print(\"\\nDimensões de X:\", X.shape)\n","print(\"Dimensões de y:\", y.shape)\n","\n","# -----------------------------\n","# 4. Pré-processamento\n","# -----------------------------\n","# Identificar feature categórica\n","cat_index = 0\n","\n","# Pipeline de transformação: OneHotEncoding + Padronização\n","preprocessor_pipeline = Pipeline([\n","    ('onehot', ColumnTransformer(\n","        transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), [cat_index])],\n","        remainder='passthrough'\n","    )),\n","    ('scaler', StandardScaler(with_mean=False))\n","])\n","\n","X_processed = preprocessor_pipeline.fit_transform(X)\n","\n","# Codificação da variável alvo\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","class_names = label_encoder.classes_\n","\n","print(\"\\nDimensões após pré-processamento:\", X_processed.shape)\n","print(\"Classes do alvo:\", class_names)\n","\n","# -----------------------------\n","# 5. Divisão entre treino e teste\n","# -----------------------------\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_processed, y_encoded, test_size=0.2, random_state=123\n",")\n","print(\"\\nConjunto de treino:\", X_train.shape)\n","print(\"Conjunto de teste:\", X_test.shape)\n","\n","# -----------------------------\n","# 6. Treinamento de modelos\n","# -----------------------------\n","# Regressão Logística\n","log_model = LogisticRegression(max_iter=1000)\n","log_model.fit(X_train, y_train)\n","\n","# Naive Bayes\n","nb_model = GaussianNB()\n","nb_model.fit(X_train.toarray(), y_train)\n","\n","# Árvore de Decisão\n","tree_model = DecisionTreeClassifier(random_state=123)\n","tree_model.fit(X_train, y_train)\n","\n","# Random Forest\n","rf_model = RandomForestClassifier(random_state=123)\n","rf_model.fit(X_train, y_train)\n","\n","# -----------------------------\n","# 7. Função de avaliação\n","# -----------------------------\n","def avaliar_modelo(y_true, y_pred, classes, nome_modelo):\n","    acc = accuracy_score(y_true, y_pred)\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    print(f\"\\n--- Avaliação do Modelo: {nome_modelo} ---\")\n","    print(f\"Acurácia: {acc*100:.2f}%\")\n","\n","    plt.figure(figsize=(5,4))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n","                xticklabels=classes, yticklabels=classes)\n","    plt.title(f\"Matriz de Confusão - {nome_modelo}\")\n","    plt.xlabel(\"Predito\")\n","    plt.ylabel(\"Verdadeiro\")\n","    plt.show()\n","\n","# -----------------------------\n","# 8. Avaliação de cada modelo\n","# -----------------------------\n","avaliar_modelo(y_test, log_model.predict(X_test), class_names, \"Regressão Logística\")\n","avaliar_modelo(y_test, nb_model.predict(X_test.toarray()), class_names, \"Naive Bayes\")\n","avaliar_modelo(y_test, tree_model.predict(X_test), class_names, \"Árvore de Decisão\")\n","avaliar_modelo(y_test, rf_model.predict(X_test), class_names, \"Random Forest\")\n","\n","# -----------------------------\n","# 9. Salvando o melhor modelo\n","# -----------------------------\n","melhor_modelo = tree_model\n","joblib.dump(melhor_modelo, \"melhor_modelo_decision_tree.pkl\")\n","joblib.dump(preprocessor_pipeline, \"preprocessor_pipeline.pkl\")\n","print(\"\\nModelo e pipeline salvos com sucesso!\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"AY4hMkWXpdEA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PB2gmv3CqPmw"},"execution_count":null,"outputs":[]}]}